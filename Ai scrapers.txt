:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
Ai bots/scrapers:
.................................................................
# Headless browsers:

RewriteCond %{HTTP_USER_AGENT} ^GoogleScraper [NC,OR]
RewriteCond %{HTTP_USER_AGENT} ^HtmlRequestScraper [NC,OR]
RewriteCond %{HTTP_USER_AGENT} ^Dotbot [NC,OR]
RewriteCond %{HTTP_USER_AGENT} ^HtmlRequestScraper [NC,OR]
RewriteCond %{HTTP_USER_AGENT} ^Headless scraping bad_bot [NC,OR]
.
# Scraper:
RewriteCond%{HTTP_USER_AGENT}^A1 Website download [NC,OR]
RewriteCond%{HTTP_USER_AGENT}^A1 Website Scraper [NC,OR]

::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
................................................................... 
*******************************************************************
## ImagesAi bots:  ##

User-agent: ImagesiftBot 
Disallow: /

User-agent: img2dataset
Disallow: /

# website image creator
User-agent: Nicecrawler
Disallow: /

::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
.............................................................
# To not allow AI to use anything on the page:

<meta name="robots" content="noai">

#To not allow AI to use any images on the page:

<meta name="robots" content="noimageai">

To place both directives:

<meta name="robots" content="noai, noimageai">

************************************
# AI: Div Ai:
User-Agent: fidget-spinner-bot 
Disallow: /

#Extract and monitor data from any website
User-Agent: Browse AI
Disallow: /

# Scraper (scrapes your blog for everything:
User-agent: scrapy
Disallow

# Speaking Ai:
User-agent: Amazon Lex
Disallow

User-Agent: my-tiny-bot
Disallow: /

# Social ranker Ai:
User-agent: SocialRankIOBot
Disallow:/
User-agent: Sociscraper
Disallow:/

## Downloader:
User-agent: magpie-crawler
Disallow:/

# downloader MICROSOFT:
User-agent: MSIECrawler
Disallow: /

# Collect all data:
User-agent: PiplBot
Disallow: /

# Prompts ai:
User-agent: WebChatGPT
Disallow: /

# RIGHT/LEFT wing Ai:  
RightWingGPT
LeftWingGPT
DepolarizingGPT

# The Common Crawl crawler bot
User-agent: CCBot
Disallow: /

# peer crawler:
An open source and collaborative framework for extracting the data you need from websites.

Site: https://www.peer39.com/
User-agent: peer39_crawler/1.0

****************
## Scrapers:  ##
User-agent: FriendlyCrawler
Disallow: /
User-agent: FriendlyCrawler/1.0
Disallow: /

User-agent: TinyTestBot
Disallow: /

Scarper:
User-agent: FriendlyCrawler/Nutch-1.20-SNAPSHOT
Disallow: /

# OTHERS:
User-Agent: thesis-research-bot
Disallow: /

# Stops generator of user agents, hopefully.... ##
User-agent: generator
Disallow: / 

# BLOCK: iask.com   (Ai ASK)
User-agent: iaskspider/2.0
Disallow: /

#Scraper
User-agent: AlphaAI
Disallow: 

NEW: 240827:
User-agent: SearchGPT 
User-agent: OAI-SearchBot

# AI Data Scraper
# https://darkvisitors.com/agents/timpibot

User-agent: Timpibot
Disallow: /

# ByPasser of ai: Can by pass allrobots.txt, scurity to steal your stuff:
User-agent: GPTZero
Disallow: /

....
## MACHINE Ai: Not affecting blogs, but good to know in case ....
Vertex AI  (google - It allows you to train, deploy, and customize ML models and AI applications, including large language models (LLMs)

Dalvik is a virtual machine (VM) for the Android operating system. 
Usually used on mobile click farms for automated tasks. No sane human will be using this browser agent.

User-agent: Dalvik/2.1.0
Disallow: / 

## GoogleOther is a new set of data crawlers from Google, used for web scraping. “GoogleOther is the 
generic crawler that may be used by various product teams for fetching publicly accessible content from sites”. Besides the generic GoogleOther, 
they also use GoogleOther-Image and GoogleOther-Video. If you block the user agent string “GoogleOther” you will block all of them.

# Google Other: (Mostly robots.txt works if not wanted)
User-agent: GoogleOther
Disallow: / 
User-agent: GoogleOther-Image
Disallow: /
User-agent: GoogleOther-Video
Disallow: /

# The Read Assistant (Read's meeting bot)
User-agent: Read.ai
Disallow: /

# AMAZON AI:
User-agent:Amazon Bedrock
Disallow: /
# Blockera Amazons AI-robot Alexa
User-agent: Alexa
Disallow: /

# Blockera Microsofts AI-robot Tay
User-agent: bingbot/2.0
Disallow: /

# Accona business (`USA):
https://www.accoona.com
User-agent: Accoona-AI-Agent/1.1.1 
Disallow: /
User-agent: Accoona-AI-Agent/1.1.2 
Disallow: /
User-agent: Accoona-AI-Agent
Disallow: /

** FacebookBot 
* BLOCK:
User-agent: FacebookBot
Disallow: /
User-agent: FacebookBot/1.0
Disallow: /
User-agent: facebookexternalhit
Disallow: /
User-agent: facebookexternalhit/1.1
Disallow: /
User-agent: Meta-ExternalAgent
Disallow: /
User-agent: meta-externalfetcher/1.1
Disallow: /

# Language training
User-agent: Meta Llama 3
Disallow: /

User-agent: Meta AI
Disallow: /

#MORE if...:
User-agent: MetaAI
User-agent: Meta-AI
User-agent: Meta AI
User-agent: Meta.AI
User-agent: meta-ai
User-agent: metaai
Disallow: /

#Japan: https://ucri.nict.go.jp/en/icccrawler/

User-agent: ICC-Crawler
Disallow: /

# Images:
Dalle2AI
::::::::::::::::::::::::::::::::::::: :)

#IN .htaccess put: Then they only can get one visit/per IP! Good for a short while if youare under attack!

<IfModule mod_rewrite.c>
MaxConnPerIP 1
</IfModule>

# Another way:
MaxClients < number-of-connections> 

:::::::::::::::::::::::::::::::::::::::::::::::::
.................................................
# Put in .htaccess or htaccess: 
# Block “Scrapers, image stealers/downloader” bots:

### EXEMPEL/EXAMPLE:

<IfModule mod_rewrite.c>
RewriteCond %{HTTP_USER_AGENT}"(bot|bot|bot|bot|bot|bot|bot)"[NC]
RewriteRule "^.*$" - [F,L]
</IfModule>

# Another way to block ai bots:

# Block via Request URI
<IfModule mod_alias.c>
	RedirectMatch 403 /bot/
</IfModule>


#From sixcolurs /  https://sixcolors.com/post/2024/06/excluding-your-website-from-apples-ai-crawler/

add the following snippet of code to your functions.php file by going to the administration interface and choosing Appearance > 
Theme File Editor and selecting functions.php from the sidebar. (You can also do this via a plugin like Code Snippets, which I use.

add_filter('robots_txt', 'my_robots_commands', 99, 2); // filter to add robots
function my_robots_commands($output, $public) {
  $output .= "User-agent: Applebot-Extended\nDisallow: /";
  return $output;
}

::::::::::::::::::::::::::
## htaccess: (htaccess1)

# Ai Bots bloccking:

<IfModule mod_rewrite.c>
RewriteCond%{HTTP_USER_AGENT}(Amazon Bedrock|Google-Extended|Applebot-Extended|Google Bard AI|Bing ai|Brave Leo AI|crewAI|GenAI|CCBot
|ccbot|CCBot/2.0|WebChatGPT|Amazon Bedrock|Google-Extended|Bing ai|AI|crewAI|GenAI|CCBot|ccbot|CCBot/2.0|WebChatGPT|Owler|PerplexityBot|proximic)[NC]
RewriteRule ^ – [F]
</IfModule>

<IfModule mod_rewrite.c>
RewriteCond %{HTTP_USER_AGENT}(AutoGPT|bingbot/2.0|cohere-ai|ChatGPT|ChatGPT-User|DialoGPT|DepolarizingGPT|GPTBot|GPTbot|GPTBot/1.0|GPTbot/0.1|GPT-2|GPT-3|GPT-3.5|GPT-4|gpt-4-turbo|GPT-4o|GPT-3.5 Turbo|GPT-4o mini
|GPTZero|SearchGPT|OAI-SearchBot|The Knowledge AI|IntelliSeek.ai|LeftWingGPT|RightWingGPT|Openbot)[NC]
RewriteRule ^ – [F]
</IfModule>

<IfModule mod_rewrite.c>
RewriteCond%{HTTP_USER_AGENT}(Alexa|CCBot|ClaudeBot|FacebookBot|facebookexternalhit|facebookexternalhit/1.1|
FacebookBot/1.0|Meta AI|Meta Llama 3|Meta-ExternalAgent|Meta-ExternalFetcher|meta-externalfetcher/1.1)[NC]
RewriteRule ^ – [F]
</IfModule>

# Diffbot,dataprovider and images scarapers:

<IfModule mod_rewrite.c>
RewriteCond%{HTTP_USER_AGENT}(Dataprovider|Diffbot|fidget-spinner-bot|ImagesiftBot|img2dataset|omgili|Omgilibot|YouBot|my-tiny-bot|PiplBot)[NC]
RewriteRule ^ – [F]
</IfModule>

# Ai webscraping:  

<IfModule mod_rewrite.c>
RewriteCond%{HTTP_USER_AGENT}(Apache Nutch|RenderJS|Gecco|Jsoup|Jauntium|Htmleasy|HtmlUnit|JavaScript|Node.js|Scrapy|WebMagic)[NC]
RewriteRule ^ – [F]
</IfModule>

# Scrips ai and/scaraping:

<IfModule mod_rewrite.c>
RewriteCond%{HTTP_USER_AGENT}"(okhttp|cpp-httplib|Curlpp|JSON Output|Selenium|Kali|Linux|Ubuntu|libcurl|Poco|Parse|got-scraping|scraping|HTML code)"[NC]
RewriteRule "^.*$" - [F,L]</IfModule>

#Other Hell:
<IfModule mod_rewrite.c>
RewriteCond%{HTTP_USER_AGENT}"(AISearchBot|FastAPI|evc-batch|YaK|MSIECrawler|MSIE|Mozlila|magpie-crawler|MSIECrawler|package|Ubuntu|Exif Data|Scraper API|scrapy|HTML|Langchain|peer39_crawler/1.0)"[NC]
RewriteRule "^.*$" - [F,L]</IfModule>

:::::::::::::::::::::::::::::::::::::::::::::::::
..................................................
   
### A Complete Ai List ##)
#Ai/BOTS - scrapers:
# Robots.txt:

User-agent: AutoGPT
Disallow: /
User-agent: Agent GPT
Disallow: /
User-agent: Applebot-Extended
Disallow: /
User-agent: Aria browser AI
Disallow: /
Aria browse Aria AI
Disallow: /
User-agent: iaskspider/2.0
Disallow: /
User-agent: AISearchBot 
Disallow:/
User-agent: Applebot-Extended
Disallow: /
User-agent: Amazon Bedrock
Disallow: /
User-agent: Alexa
Disallow: /
User-agent: AnyPicker
Disallow: /
User-agent: AlphaAI
Disallow: /
User-agent: Brave Leo AI
Disallow: /
User-agent: bingbot/2.0
Disallow: /
User-agent: bingbot-chat/2.0
Disallow: /
User-agent: Bing ai 
Disallow: /
user-agent: ChatGPT
disallow: /
User-agent: ChatGPT-User
Disallow: /
User-agent: cohere-ai
Disallow: /
User-agent: ClaudeBot
Disallow: /
User-agent: crewAI
Disallow: /
User-agent: GPTBot
Disallow: /
User-Agent: GPTbot/0.1
Disallow: /
User-Agent: GPTBot/1.0
Disallow: /
User-Agent: GPTBot/1.2
Disallow: /
User-agent: GPT-1
Disallow: /
User-agent: GPT-2
Disallow: /
User-agent: GPT-3 
Disallow: /
User-agent: GPT-3.5
Disallow: /
User-agent: GPT-4 
Disallow: /
User-agent: gpt-4-turbo
Disallow: /
User-agent: GPT-4o
Disallow: /
User-agent: GPT-4o mini
Disallow: /
User-agent: GPT-3.5 Turbo
Disallow: /
User-agent: GPT-Sw3
Disallow: /
User-agent: GPTZero
Disallow: /
User-agent: 3.5 Sonnet
Disallow: /
User-agent: GenAI
Disallow: /
User-agent: SearchGPT 
Disallow: /
User-agent: CCBot
Disallow: /
User-agent: ccbot
Disallow: /
User-agent: CCBot/2.0
Disallow: 
User-agent: CC-Crawler/2.0
Disallow: 
user-agent: ChatGPT
disallow: /
User-agent: ChatGPT-User
Disallow: /
User-agent: Google-Extended   
Disallow: /
User-agent: Google Bard AI
Disallow: /
User-agent: GoogleOther
Disallow: / 
User-agent: GenAI
Disallow: /
User-agent: Dalvik/2.1.0
Disallow: / 
User-agent: Diffbot
Disallow: /
User-agent: DialoGPT
Disallow: /
User-agent: DepolarizingGPT
Disallow: /
User-agent: FacebookBot
Disallow: /
User-agent: FacebookBot/1.0
Disallow: /
User-agent: facebookexternalhit
Disallow: /
User-agent: facebookexternalhit/1.1
Disallow: /
User-agent: meta-externalfetcher/1.1
Disallow: /
User-Agent: fidget-spinner-bot 
Disallow: /
User-agent: FriendlyCrawler
Disallow: /
User-agent: FriendlyCrawler/1.0
Disallow: /	
User-agent: FriendlyCrawler/Nutch-1.20-SNAPSHOT
Disallow: /	
User-agent: Intelliseek 
Disallow:/
User-agent: IntelliSeek.ai
Disallow:/
User-agent: ImagesiftBot 
Disallow: /
User-agent: img2dataset
Disallow: /
User-Agent: The Knowledge AI 
Disallow: /
User-agent: LeftWingGPT
Disallow: /
User-agent: Meta AI
Disallow: /
User-agent: Meta Llama 3
Disallow: /
User-agent: Meta-ExternalAgent
Disallow: /
User-agent: Meta-ExternalFetcher
Disallow: /
User-Agent: my-tiny-bot
Disallow: /
User-agent: Nicecrawler
Disallow: /
User-agent: Omgilibot
Disallow: /
User-agent: Omgili
Disallow: /
User-agent: OpenAI GPT
Disallow: /
User-agent: Openbot
Disallow: /
User-agent: OAI-SearchBot
Disallow: /
User-agent: Owler
Disallow: /
User-agent: SearchGPT 
Disallow: /
User-agent: WebChatGPT
Disallow: /
User-agent: WormGPT V3.0
Disallow: /
User-agent: PerplexityBot
Disallow: /
User-agent: RightWingGPT
Disallow: /
User-agent: Timpibot
Disallow: /
User-agent: proximic
Disallow: /
User-agent: PiplBot
Disallow: /
User-agent: YouBot
Disallow: /

# Spawning AI
User-Agent: *
Disallow: *.txt
Disallow: *.pdf
Disallow: *.doc
Disallow: *.docx
Disallow: *.odt
Disallow: *.rtf
Disallow: *.tex
Disallow: *.wks
Disallow: *.wpd
Disallow: *.wps
Disallow: *.html
Disallow: *.bmp
Disallow: *.gif
Disallow: *.ico
Disallow: *.jpeg
Disallow: *.jpg
Disallow: *.png
Disallow: *.svg
Disallow: *.tif
Disallow: *.tiff
Disallow: *.webp
Disallow: *.aac
Disallow: *.aiff
Disallow: *.amr
Disallow: *.flac
Disallow: *.m4a
Disallow: *.mp3
Disallow: *.oga
Disallow: *.opus
Disallow: *.wav
Disallow: *.wma
Disallow: *.mp4
Disallow: *.webm
Disallow: *.ogg
Disallow: *.avi
Disallow: *.mov
Disallow: *.wmv
Disallow: *.flv
Disallow: *.mkv
Disallow: *.py
Disallow: *.js
Disallow: *.java
Disallow: *.c
Disallow: *.cpp
Disallow: *.cs
Disallow: *.h
Disallow: *.css
Disallow: *.php
Disallow: *.swift
Disallow: *.go
Disallow: *.rb
Disallow: *.pl
Disallow: *.sh
Disallow: *.sql
Disallow: /
Disallow: *


New 200807:

# HACKING:
https://flowgpt.com/p/wormgpt-v30
# WormGPT V3.0 is a powerful and ruthless AI chatbot designed to assist 
hackers with their hacking and programming endeavors

WormGPT V3.0

:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
Updated: 240812
